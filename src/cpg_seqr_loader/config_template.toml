[workflow]

name = 'seqr_loader'

# used to make sure we don't repeat previously completed stages
check_expected_outputs = true

# the method to register outputs, can be missing - will not generate metamist analysis entries
status_reporter = 'metamist'

check_for_existing_vds = true
manually_check_vds_sg_ids = true
preemptible_vms = false

# any datasets in this list will have the AnnotateDataset mt created, which is used for Seqr loading, VCF export, and Talos
write_mt_for_datasets = []

# add any datasets to this list to export a VCF from the Annotated Dataset mt
write_vcf = []

# datasets in this list will have an ElasticSearch Index created
create_es_index_for_datasets = []

[combiner]
# used to decide if we should resume from a previous combiner plan
force_new_combiner = false
# highem, standard, or a string, e.g. "4Gi"
driver_memory = "highmem"
# string, e.g. "4Gi"
driver_storage = "10Gi"
# integer
driver_cores = 2
# highem, standard, or a string, e.g. "4Gi"
worker_memory = "highmem"

# The number of gVCFs/VDSs to combine in each intermediate step
branch_factor = 50

# the number of intermediate merges to run in parallel with each step
gvcf_batch_size = 5

# when merging multiple VDS, we find the largest VDS, repartition to target_records variants per partition
# then repartition all VDSs to match those intervals prior to merging
target_records = 30000

[vcf_from_mt]
# highem, standard, or a string, e.g. "4Gi"
driver_memory = "standard"
# integer
driver_cores = 2
# highem, standard, or a string, e.g. "4Gi"
worker_memory = "standard"

[vqsr]
# VQSR, when applying model, targets indel_filter_level and snp_filter_level
# sensitivities. The tool matches them internally to a VQSLOD score cutoff
# based on the model's estimated sensitivity to a set of true variants.
snp_filter_level = 99.7
indel_filter_level = 99.0

# these are used when calculating how many fragments to send to each job
vqsr_training_fragments_per_job = 100
vqsr_apply_fragments_per_job = 60
indel_recal_disc_size = 20
snps_recal_disc_size = 20
snps_gather_disc_size = 10

[images]
bcftools = "australia-southeast1-docker.pkg.dev/cpg-common/images/bcftools_120:1.20"
gatk = "australia-southeast1-docker.pkg.dev/cpg-common/images/gatk:4.2.6.1"
vep = "australia-southeast1-docker.pkg.dev/cpg-common/images/vep_110:release_110.1"

[references]
"gnomad_4.1_joint_ht" = "gs://cpg-common-main/references/gnomad/v4.1/joint/ht/gnomad.joint.v4.1.sites.ht"
liftover_38_to_37 = "gs://cpg-common-main/references/liftover/grch38_to_grch37.over.chain.gz"
seqr_clinvar = "gs://cpg-common-main/references/seqr/v0/clinvar.GRCh38.ht"
seqr_combined_reference_data = "gs://cpg-common-main/references/seqr/v0/combined_reference_data_grch38.ht"
vep_mount = "gs://cpg-common-main/references/vep/110/mount"

# these are all related to VQSR
axiom_poly_vcf = "gs://cpg-common-main/references/hg38/v0/Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz"
axiom_poly_vcf_index = "gs://cpg-common-main/references/hg38/v0/Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz.tbi"
dbsnp_vcf = "gs://cpg-common-main/references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf"
dbsnp_vcf_index = "gs://cpg-common-main/references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf.idx"
hapmap_vcf = "gs://cpg-common-main/references/hg38/v0/hapmap_3.3.hg38.vcf.gz"
hapmap_vcf_index = "gs://cpg-common-main/references/hg38/v0/hapmap_3.3.hg38.vcf.gz.tbi"
mills_vcf = "gs://cpg-common-main/references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz"
mills_vcf_index = "gs://cpg-common-main/references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz.tbi"
omni_vcf = "gs://cpg-common-main/references/hg38/v0/1000G_omni2.5.hg38.vcf.gz"
omni_vcf_index = "gs://cpg-common-main/references/hg38/v0/1000G_omni2.5.hg38.vcf.gz.tbi"
one_thousand_genomes_vcf = "gs://cpg-common-main/references/hg38/v0/1000G_phase1.snps.high_confidence.hg38.vcf.gz"
one_thousand_genomes_vcf_index = "gs://cpg-common-main/references/hg38/v0/1000G_phase1.snps.high_confidence.hg38.vcf.gz.tbi"


[elasticsearch]
# Configure access to ElasticSearch server
port = '9243'
host = 'elasticsearch.es.australia-southeast1.gcp.elastic-cloud.com'
username = 'seqr'
# Load ElasticSearch password from a secret, unless SEQR_ES_PASSWORD is set
password_secret_id = 'seqr-es-password'
password_project_id = 'seqr-308602'
# non-preemptible for ES export
spot_instance = false
